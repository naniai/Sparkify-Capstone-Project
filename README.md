# DSND-Sparkify-Capstone-Project

## 介绍
我完成了这个Capstone项目，是Udacity数据科学家纳米学位要求的一部分。

在该项目中，我使用了音乐流服务Sparkify的用户日志数据和Apache Spark Python API PySpark来预测用户流失。我使用减少后的128 MB数据集在本地台式机上开始进行分析。

除了使用Spark之外，与我过去处理过的其他项目相比，用于该项目的特殊数据类型以及将Notebook部署到Amazon Web Services（AWS）的Elastic Map Reduce（EMR）集群的需求都被证明有些挑战。

使用用户日志数据的挑战之一是，尽管单个用户拥有大量行，但最终需要在应用机器学习算法之前将每个用户的行减少为单个行。

事实证明，处理本地和群集性能问题是另一个挑战。

## 数据集
完整的数据集大小为12GB，由于时间和计算调价的限制，我们选取了它的一个迷你子集，大小约为几百兆。

## 使用到的库
	* pandas, numpy, matplotlib
	* Spark for Python - pyspark
	* Amazon Web Services

## 项目流程
该项目从分析整个数据集的一小部分开始。首先，删除了所有不能归因于注册用户的交互情况，并给出了简化数据集的简要概述。

然后，定义流失，创建许多不同的聚合特征（这样对于每个用户只需要保留一行），然后在流失用户和非流失用户这两组用户之间比较这些特征。在此过程中，确定了随后用于机器学习模型的特征。

在下一部分中，简化后的数据集或完整数据集将减少为每位客户仅使用先前标识的相关功能的一行。然后，通过消除数字特征的离群值，使用最小-最大缩放对数字特征进行缩放并应用于分类特征来进一步处理这些特征。

接下来，将准备好的数据集分为训练和测试集。然后，该数据用于比较几种不同的分类机器学习算法：逻辑回归，随机森林模型。在精简数据集的情况下，随机森林模型效果最佳。

最后，对最佳模型进行超参数调整，简要讨论功能重要性，并提供简短结论。

## 项目结果
比较模型：
	* LogisticRegression (best F1-score 0.61)
	* RandomForestClassifier (best F1-score 0.76)
分别采用 **逻辑回归**, **随机森林** 两种监督学习模型，结果**随机森林**模型效果更好

## 博客文章
我写了一篇有关该项目的博客文章，您可以在[大数据分析和预测用户流失 - 简书](https://www.jianshu.com/p/41be26091c23)找到。这篇博客文章提供了对该项目的更广泛的概述，并提供了更多有关为什么预测用户流失，大数据和Spark问题的背景信息。

## 致谢和鸣谢
这个Capstone项目以我在Udacity数据科学家纳米学位中获得的整体知识以及Udacity提供的Spark课程为基础，Sparkify数据由Udacity及其合作伙伴Insight Data Science提供。

## 关于
Udacity数据科学家使用Spark的Nanodgree Capstone项目。